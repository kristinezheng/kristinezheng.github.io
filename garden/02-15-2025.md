# #1: about love, automation, and writing 
1. [love (& time)](#love_time)
2. [automation](#automation)
3. [writing](#writing)


## love & time <div id='love_time'/>
Yesterday, I watched the movie [About Time (2013)](https://en.wikipedia.org/wiki/About_Time_(2013_film)). 

* 
* [The Wild Robot](https://en.wikipedia.org/wiki/The_Wild_Robot): can AI learn emotions and break out of programming in this way? it would be so cool to understand animals in this way ... 

## automation
["Why Automate This? Exploring the Connection between Time Use, Well-being and Robot Automation Across Social Groups"](https://hri1260.github.io/why-automate-this/):
* Outcome: Authors explore three datasets to find the relationship between tasks people would want robots to do for them, time spent on tasks, and emotions experienced on activities (respectively). Overall, there is some relatonship between desire to automate with a lack of happiness experienced for men. For women, there is a small correlation between how stressful an activity is and desire to automate. (Most of the tasks are related to housework.)

Thoughts and connections: 
* How does a person's age/generation affect what they would like to automate? What about automation with *robots* (perhaps physical tasks) or *AI* (perhaps more digital/mental tasks)? 
    * I could imagine that people in training would want a robot/AI to help them with tasks they are less confident with but hope to do well in (e.g. students writing graded essays). 
* What is the relationship between gender (identity) and motivation for tasks? I could imagine that for some (e.g. women, parents), duty (maybe stressful) may come before happiness experienced. This could help explain the current results? 
* Many times in history, technology for something actually increased workload and stress rather than helping (e.g. the invention of the cotton gin with slavery in american cotton plantations). Automating something might not increase happiness or wellbeing -- rather it might just increase the productivity expectations. 
* Many people I know use copilot, cursor, and other embedded AI code helpers. Why? On the other hand, why do I use llms (with programming) and why don't I want it to be integrated with vscode/ide? 
    * Coding can be tedious (boring, lack of happiness) and requires contiuous learning (especially as new languages and methods are developed). As long as one as a sort of *pseudocode*, it is very easy to ask a llm to fill in the details. On the other hand, if one doesn't really know what they want, they might keep prompting an llm to ask for ideas and refine them. 
    * The idea of an embedded AI helper could seem appealing since it takes some of the "cognitive strain" off of keeping track of different treads, looking for particular code areas, writing clean/organized code, and more. Many friends seem to enjoy the fact that they can work *faster* and have nicer code. 
    * I don't want to become too reliant on another's "intelligence." Sometimes it is hard to parse results if it is personally created with through thinking and iterations. I feel as if I am still learning many things and only want to ask an llm fairly pointed questions (many do end up being repetitive R tasks...) rather than constantly have another set of eyes on the entire project. Generally, I feel worried about losing practice in "high cognitive load" tasks and want to improve my writing/coding skills. 
* What could I imagine automated? I do agree that general cleaning could be helpful to be automated -- perhaps a robot could help people dispose of waste correctly (actually recycle and compost) & perhaps living conditions could be improved across the board. Pollution and industry waste disproportionally affects BIPOC ([WGS.275 gender, race, and climate justice](https://wgs.mit.edu/spring2022/wgs275)). 

## writing

* Studying Herbert Clark's [Everyone Can Write Better](https://www.lri.fr/~anab/teaching/CareerSeminar/Clark.pdf)

------------
Last updated: 02/16/2025
Created: 02/16/2025
